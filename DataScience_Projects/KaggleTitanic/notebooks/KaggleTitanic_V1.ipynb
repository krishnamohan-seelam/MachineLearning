{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from mltools.mlcommon import one_hot_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory = pathlib.Path().resolve().parent\n",
    "data_directory  = project_directory.joinpath('data/raw')\n",
    "report_directory  = project_directory.joinpath('reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train.csv'\n",
    "test_file  = 'test.csv'\n",
    "report_file = 'profile_report.html'\n",
    "train_filepath = data_directory.joinpath(train_file)\n",
    "test_filepath = data_directory.joinpath(test_file)\n",
    "report_filepath = report_directory.joinpath(report_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_describe(df):\n",
    "    describe_df  = df.describe(include='all').T\n",
    "    describe_df['Null_Count']= df.isnull().sum()\n",
    "    return describe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_cabin(deck_level):\n",
    "    if (deck_level =='X'):\n",
    "        return 'No'\n",
    "    else: \n",
    "        return 'Yes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweak_dataset(df):\n",
    "    df['FamilySize'] = df[\"SibSp\"] +df[\"Parch\"] + 1\n",
    "    df['Embarked'].fillna('S' ,inplace =True)\n",
    "    df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.',expand =False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess', 'Sir', 'Jonkheer', 'Dona','Don'], 'Other')\n",
    "    df['Title'] = df['Title'].replace(['Capt', 'Col', 'Dr', 'Major', 'Rev'],'Officer')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "    df['Cabin'].fillna('XXX' ,inplace=True)\n",
    "    df['Deck_Level'] = df['Cabin'].apply(lambda x : x[0]) \n",
    "     \n",
    "    df.drop(['Name','Ticket','Cabin',],inplace=True,axis =1) \n",
    "    #df = pd.get_dummies(df,drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_filepath)\n",
    "test_df = pd.read_csv(test_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(train_df).to_file(report_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = tweak_dataset(train_df)\n",
    "test_df = tweak_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_ages =train_df.groupby(['Sex','Pclass','Title','SibSp','Parch'])['Age'].median()\n",
    " \n",
    "def fill_missing_age(row):\n",
    "    if pd.isnull(row['Age']):\n",
    "        return median_ages[row['Sex'],row['Pclass'],row['Title'] ,row['SibSp'] ,row['Parch']]\n",
    "    else:\n",
    "        return row['Age']\n",
    "\n",
    "train_df['Age']=train_df.apply(fill_missing_age,axis=1) \n",
    " \n",
    "\n",
    "median_ages_again =train_df.groupby(['Sex','Pclass','Title'])['Age'].median()\n",
    "median_ages_again[median_ages_again.isnull()]\n",
    "\n",
    "def fill_missing_age_again(row):\n",
    "    if pd.isnull(row['Age']):\n",
    "        return median_ages_again[row['Sex'],row['Pclass'],row['Title']]\n",
    "    else:\n",
    "        return row['Age']\n",
    "    \n",
    "train_df['Age']=train_df.apply(fill_missing_age_again,axis=1) \n",
    "test_df['Age']=test_df.apply(fill_missing_age_again,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>Null_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PassengerId</td>\n",
       "      <td>418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1100.5</td>\n",
       "      <td>120.81</td>\n",
       "      <td>892</td>\n",
       "      <td>996.25</td>\n",
       "      <td>1100.5</td>\n",
       "      <td>1204.75</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pclass</td>\n",
       "      <td>418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.26555</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Sex</td>\n",
       "      <td>418</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.5766</td>\n",
       "      <td>13.2343</td>\n",
       "      <td>0.17</td>\n",
       "      <td>21.25</td>\n",
       "      <td>27</td>\n",
       "      <td>36.375</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SibSp</td>\n",
       "      <td>418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.89676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Parch</td>\n",
       "      <td>418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.6272</td>\n",
       "      <td>55.9076</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>31.5</td>\n",
       "      <td>512.329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Embarked</td>\n",
       "      <td>418</td>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FamilySize</td>\n",
       "      <td>418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.83971</td>\n",
       "      <td>1.51907</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Title</td>\n",
       "      <td>418</td>\n",
       "      <td>6</td>\n",
       "      <td>Mr</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Deck_Level</td>\n",
       "      <td>418</td>\n",
       "      <td>8</td>\n",
       "      <td>X</td>\n",
       "      <td>327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count unique   top freq      mean       std   min     25%  \\\n",
       "PassengerId   418    NaN   NaN  NaN    1100.5    120.81   892  996.25   \n",
       "Pclass        418    NaN   NaN  NaN   2.26555  0.841838     1       1   \n",
       "Sex           418      2  male  266       NaN       NaN   NaN     NaN   \n",
       "Age           418    NaN   NaN  NaN   29.5766   13.2343  0.17   21.25   \n",
       "SibSp         418    NaN   NaN  NaN  0.447368   0.89676     0       0   \n",
       "Parch         418    NaN   NaN  NaN  0.392344  0.981429     0       0   \n",
       "Fare          417    NaN   NaN  NaN   35.6272   55.9076     0  7.8958   \n",
       "Embarked      418      3     S  270       NaN       NaN   NaN     NaN   \n",
       "FamilySize    418    NaN   NaN  NaN   1.83971   1.51907     1       1   \n",
       "Title         418      6    Mr  240       NaN       NaN   NaN     NaN   \n",
       "Deck_Level    418      8     X  327       NaN       NaN   NaN     NaN   \n",
       "\n",
       "                 50%      75%      max  Null_Count  \n",
       "PassengerId   1100.5  1204.75     1309           0  \n",
       "Pclass             3        3        3           0  \n",
       "Sex              NaN      NaN      NaN           0  \n",
       "Age               27   36.375       76           0  \n",
       "SibSp              0        1        8           0  \n",
       "Parch              0        0        9           0  \n",
       "Fare         14.4542     31.5  512.329           1  \n",
       "Embarked         NaN      NaN      NaN           0  \n",
       "FamilySize         1        2       11           0  \n",
       "Title            NaN      NaN      NaN           0  \n",
       "Deck_Level       NaN      NaN      NaN           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df_describe(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-85d53ae9eb86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Check' is not defined"
     ]
    }
   ],
   "source": [
    "Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(-999,inplace=True)\n",
    "test_df.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Fare           float64\n",
       "Embarked        object\n",
       "FamilySize       int64\n",
       "Title           object\n",
       "Deck_Level      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Title</th>\n",
       "      <th>Deck_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare  \\\n",
       "0            1         0       3    male  22.0      1      0   7.2500   \n",
       "1            2         1       1  female  38.0      1      0  71.2833   \n",
       "2            3         1       3  female  26.0      0      0   7.9250   \n",
       "3            4         1       1  female  35.0      1      0  53.1000   \n",
       "4            5         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  Embarked  FamilySize Title Deck_Level  \n",
       "0        S           2    Mr          X  \n",
       "1        C           2   Mrs          C  \n",
       "2        S           1  Miss          X  \n",
       "3        S           2   Mrs          C  \n",
       "4        S           1    Mr          X  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-85d53ae9eb86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Check' is not defined"
     ]
    }
   ],
   "source": [
    "Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset =pd.concat(objs=[train_df, test_df], axis=0,sort=True).reset_index(drop=True)  \n",
    "full_dataset[\"Pclass\"] = full_dataset[\"Pclass\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =full_dataset[full_dataset['Survived'].notnull()]\n",
    "train_y = full_dataset[full_dataset['Survived'].notnull()]['Survived']\n",
    "test_dataset =full_dataset[full_dataset['Survived'].isnull()]\n",
    "#train_dataset[\"Survived\"] = train_dataset[\"Survived\"].astype(\"int\")\n",
    "test_passengers = test_dataset['PassengerId']\n",
    "train_dataset.drop(labels=[\"Survived\",'PassengerId'],axis = 1,inplace=True)\n",
    "test_dataset.drop(labels=[\"Survived\",'PassengerId'],axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_features_index = np.where(train_dataset.dtypes != float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import  train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_dataset,train_y,test_size=0.3, random_state=42,stratify = train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier(loss_function='Logloss', custom_metric='AUC:hints=skip_train~false', metric_period=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.074246\n",
      "0:\tlearn: 0.6479511\ttest: 0.6533545\tbest: 0.6533545 (0)\ttotal: 159ms\tremaining: 2m 38s\n",
      "50:\tlearn: 0.3890499\ttest: 0.4234668\tbest: 0.4234668 (50)\ttotal: 2.86s\tremaining: 53.3s\n",
      "100:\tlearn: 0.3595710\ttest: 0.4166406\tbest: 0.4166406 (100)\ttotal: 5.38s\tremaining: 47.9s\n",
      "150:\tlearn: 0.3067121\ttest: 0.4153031\tbest: 0.4153031 (150)\ttotal: 9.1s\tremaining: 51.2s\n",
      "200:\tlearn: 0.2720220\ttest: 0.4220238\tbest: 0.4153031 (150)\ttotal: 13.7s\tremaining: 54.6s\n",
      "250:\tlearn: 0.2507957\ttest: 0.4298607\tbest: 0.4153031 (150)\ttotal: 18.6s\tremaining: 55.4s\n",
      "300:\tlearn: 0.2317035\ttest: 0.4330705\tbest: 0.4153031 (150)\ttotal: 24.5s\tremaining: 56.9s\n",
      "350:\tlearn: 0.2144146\ttest: 0.4374050\tbest: 0.4153031 (150)\ttotal: 30.9s\tremaining: 57.2s\n",
      "400:\tlearn: 0.2038210\ttest: 0.4394058\tbest: 0.4153031 (150)\ttotal: 37s\tremaining: 55.3s\n",
      "450:\tlearn: 0.1952171\ttest: 0.4412159\tbest: 0.4153031 (150)\ttotal: 41.9s\tremaining: 51s\n",
      "500:\tlearn: 0.1891056\ttest: 0.4467682\tbest: 0.4153031 (150)\ttotal: 45.9s\tremaining: 45.7s\n",
      "550:\tlearn: 0.1801966\ttest: 0.4497334\tbest: 0.4153031 (150)\ttotal: 50.2s\tremaining: 40.9s\n",
      "600:\tlearn: 0.1743758\ttest: 0.4527649\tbest: 0.4153031 (150)\ttotal: 54.7s\tremaining: 36.3s\n",
      "650:\tlearn: 0.1694711\ttest: 0.4563398\tbest: 0.4153031 (150)\ttotal: 58.6s\tremaining: 31.4s\n",
      "700:\tlearn: 0.1645891\ttest: 0.4598836\tbest: 0.4153031 (150)\ttotal: 1m 3s\tremaining: 26.9s\n",
      "750:\tlearn: 0.1603231\ttest: 0.4631322\tbest: 0.4153031 (150)\ttotal: 1m 6s\tremaining: 22.1s\n",
      "800:\tlearn: 0.1571035\ttest: 0.4665615\tbest: 0.4153031 (150)\ttotal: 1m 10s\tremaining: 17.5s\n",
      "850:\tlearn: 0.1549602\ttest: 0.4689532\tbest: 0.4153031 (150)\ttotal: 1m 14s\tremaining: 13.1s\n",
      "900:\tlearn: 0.1505691\ttest: 0.4695168\tbest: 0.4153031 (150)\ttotal: 1m 18s\tremaining: 8.63s\n",
      "950:\tlearn: 0.1477602\ttest: 0.4696476\tbest: 0.4153031 (150)\ttotal: 1m 22s\tremaining: 4.25s\n",
      "999:\tlearn: 0.1457177\ttest: 0.4719913\tbest: 0.4153031 (150)\ttotal: 1m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4153031025\n",
      "bestIteration = 150\n",
      "\n",
      "Shrink model to first 151 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ebc46c3908>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model.fit(X_train, y_train,eval_set=(X_val, y_val),cat_features=cate_features_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_data = cv(Pool(X_train,y_train,cat_features=cate_features_index),catboost_model.get_params(),fold_count=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,mean_squared_error,f1_score,recall_score,precision_score\n",
    "\n",
    "def model_evalution(model,x_train,y_train,x_test,y_test):\n",
    "    print(\"####################### model Evalution started #######################\")\n",
    "    train_pre = model.predict(x_train)\n",
    "    test_pre = model.predict(x_test)\n",
    "    train_pro = model.predict_proba(x_train)\n",
    "    test_pro = model.predict_proba(x_test)\n",
    "\n",
    "    print(\"Train Accuracy: {0} \\t Test Accuracy: {1}\".format(accuracy_score(y_train, train_pre),accuracy_score(y_test,test_pre)))\n",
    "    print(\"Train Loss: {0} \\t Test Loss: {1}\".format(mean_squared_error(y_train, train_pre),mean_squared_error(y_test,test_pre)))\n",
    "    print(\"Train AUC: {0} \\t Test AUC: {1}\".format(roc_auc_score(y_train, train_pro[:,1]),roc_auc_score(y_test,test_pro[:,1])))\n",
    "    print(\"Train F1: {0} \\t Test F1: {1}\".format(f1_score(y_train, train_pre),f1_score(y_test,test_pre)))\n",
    "    print(\"Train recall: {0} \\t Test recall: {1}\".format(recall_score(y_train, train_pre),recall_score(y_test,test_pre)))\n",
    "    print(\"Train precision: {0} \\t Test Precision: {1}\".format(precision_score(y_train, train_pre),precision_score(y_test,test_pre)))\n",
    "    print(\"Train Confusion Matrix: \\n{0} \\n Test Confusion Matrix: \\n{1}\".format(confusion_matrix(y_train, train_pre),confusion_matrix(y_test,test_pre)))\n",
    "  #f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### model Evalution started #######################\n",
      "Train Accuracy: 0.8571428571428571 \t Test Accuracy: 0.832089552238806\n",
      "Train Loss: 0.14285714285714285 \t Test Loss: 0.16791044776119404\n",
      "Train AUC: 0.9215590132496514 \t Test AUC: 0.8706972639011474\n",
      "Train F1: 0.8017817371937638 \t Test F1: 0.7643979057591622\n",
      "Train recall: 0.7531380753138075 \t Test recall: 0.7087378640776699\n",
      "Train precision: 0.8571428571428571 \t Test Precision: 0.8295454545454546\n",
      "Train Confusion Matrix: \n",
      "[[354  30]\n",
      " [ 59 180]] \n",
      " Test Confusion Matrix: \n",
      "[[150  15]\n",
      " [ 30  73]]\n"
     ]
    }
   ],
   "source": [
    "model_evalution(catboost_model,X_train, y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y =catboost_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission =pd.DataFrame({'PassengerId':test_passengers.values ,'Survived':test_y}) \n",
    "import datetime\n",
    "FORMAT = '%Y%m%d%H%M%S'\n",
    "timestamp=datetime.datetime.now().strftime(FORMAT)\n",
    "filename =\"Titanic_CatBoost\"+timestamp+\"_out.csv\"\n",
    "#submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': [1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
      " 'iterations': [100, 233, 366, 500],\n",
      " 'l2_leaf_reg': [1, 2, 3, 5, 8],\n",
      " 'learning_rate': [0.005, 0.03, 0.1]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "# Number of trees \n",
    "iterations = [int(x) for x in np.linspace(start = 100, stop = 500, num = 4)]\n",
    "# Maximum number of levels in tree\n",
    "depth = [int(x) for x in np.linspace(1, 10, num = 11)]\n",
    " \n",
    "# Minimum number of samples required to split a node\n",
    "l2_leaf_reg = [1,2,3,5,8]\n",
    "# Minimum number of samples required at each leaf node\n",
    "loss_function = ['Logloss','CrossEntropy']\n",
    "# Method of selecting samples for training each tree\n",
    "learning_rate =[0.005,0.03,0.1]\n",
    "border_count =[32,]\n",
    "ctr_border_count=[50,]\n",
    "thread_count=4\n",
    "eval_metric =[\"Precision\"]\n",
    "params = {'depth':depth,\n",
    "          'iterations':iterations,\n",
    "          'learning_rate':learning_rate, \n",
    "          'l2_leaf_reg':l2_leaf_reg,\n",
    "          #'border_count':border_count,\n",
    "          #'ctr_border_count':ctr_border_count,\n",
    "          #'thread_count':thread_count,\n",
    "          #'eval_metric':eval_metric,\n",
    "         }\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6914938\ttotal: 52.4ms\tremaining: 5.18s\n",
      "1:\tlearn: 0.6900579\ttotal: 121ms\tremaining: 5.92s\n",
      "2:\tlearn: 0.6886299\ttotal: 178ms\tremaining: 5.76s\n",
      "3:\tlearn: 0.6872271\ttotal: 217ms\tremaining: 5.22s\n",
      "4:\tlearn: 0.6858483\ttotal: 299ms\tremaining: 5.67s\n",
      "5:\tlearn: 0.6842845\ttotal: 371ms\tremaining: 5.81s\n",
      "6:\tlearn: 0.6827897\ttotal: 393ms\tremaining: 5.22s\n",
      "7:\tlearn: 0.6812319\ttotal: 440ms\tremaining: 5.06s\n",
      "8:\tlearn: 0.6796360\ttotal: 470ms\tremaining: 4.75s\n",
      "9:\tlearn: 0.6782271\ttotal: 542ms\tremaining: 4.87s\n",
      "10:\tlearn: 0.6765980\ttotal: 581ms\tremaining: 4.7s\n",
      "11:\tlearn: 0.6751050\ttotal: 638ms\tremaining: 4.68s\n",
      "12:\tlearn: 0.6736430\ttotal: 694ms\tremaining: 4.65s\n",
      "13:\tlearn: 0.6722300\ttotal: 729ms\tremaining: 4.48s\n",
      "14:\tlearn: 0.6706437\ttotal: 785ms\tremaining: 4.45s\n",
      "15:\tlearn: 0.6692662\ttotal: 824ms\tremaining: 4.33s\n",
      "16:\tlearn: 0.6678739\ttotal: 863ms\tremaining: 4.21s\n",
      "17:\tlearn: 0.6664042\ttotal: 912ms\tremaining: 4.15s\n",
      "18:\tlearn: 0.6649245\ttotal: 944ms\tremaining: 4.02s\n",
      "19:\tlearn: 0.6636354\ttotal: 992ms\tremaining: 3.97s\n",
      "20:\tlearn: 0.6622849\ttotal: 1.04s\tremaining: 3.91s\n",
      "21:\tlearn: 0.6609551\ttotal: 1.06s\tremaining: 3.76s\n",
      "22:\tlearn: 0.6596288\ttotal: 1.1s\tremaining: 3.68s\n",
      "23:\tlearn: 0.6581968\ttotal: 1.17s\tremaining: 3.7s\n",
      "24:\tlearn: 0.6568232\ttotal: 1.2s\tremaining: 3.6s\n",
      "25:\tlearn: 0.6554400\ttotal: 1.26s\tremaining: 3.57s\n",
      "26:\tlearn: 0.6541808\ttotal: 1.31s\tremaining: 3.55s\n",
      "27:\tlearn: 0.6528105\ttotal: 1.36s\tremaining: 3.51s\n",
      "28:\tlearn: 0.6514878\ttotal: 1.42s\tremaining: 3.48s\n",
      "29:\tlearn: 0.6501212\ttotal: 1.49s\tremaining: 3.47s\n",
      "30:\tlearn: 0.6487924\ttotal: 1.53s\tremaining: 3.41s\n",
      "31:\tlearn: 0.6474365\ttotal: 1.58s\tremaining: 3.36s\n",
      "32:\tlearn: 0.6462067\ttotal: 1.64s\tremaining: 3.33s\n",
      "33:\tlearn: 0.6449157\ttotal: 1.7s\tremaining: 3.3s\n",
      "34:\tlearn: 0.6436124\ttotal: 1.74s\tremaining: 3.23s\n",
      "35:\tlearn: 0.6423965\ttotal: 1.8s\tremaining: 3.19s\n",
      "36:\tlearn: 0.6412088\ttotal: 1.82s\tremaining: 3.09s\n",
      "37:\tlearn: 0.6399976\ttotal: 1.87s\tremaining: 3.06s\n",
      "38:\tlearn: 0.6388168\ttotal: 1.93s\tremaining: 3.02s\n",
      "39:\tlearn: 0.6375677\ttotal: 1.99s\tremaining: 2.99s\n",
      "40:\tlearn: 0.6363926\ttotal: 2.05s\tremaining: 2.95s\n",
      "41:\tlearn: 0.6351472\ttotal: 2.1s\tremaining: 2.9s\n",
      "42:\tlearn: 0.6338386\ttotal: 2.14s\tremaining: 2.84s\n",
      "43:\tlearn: 0.6326324\ttotal: 2.17s\tremaining: 2.77s\n",
      "44:\tlearn: 0.6314367\ttotal: 2.24s\tremaining: 2.74s\n",
      "45:\tlearn: 0.6303111\ttotal: 2.3s\tremaining: 2.7s\n",
      "46:\tlearn: 0.6291906\ttotal: 2.32s\tremaining: 2.62s\n",
      "47:\tlearn: 0.6279693\ttotal: 2.39s\tremaining: 2.59s\n",
      "48:\tlearn: 0.6267447\ttotal: 2.44s\tremaining: 2.54s\n",
      "49:\tlearn: 0.6256572\ttotal: 2.5s\tremaining: 2.5s\n",
      "50:\tlearn: 0.6244681\ttotal: 2.55s\tremaining: 2.45s\n",
      "51:\tlearn: 0.6234294\ttotal: 2.6s\tremaining: 2.4s\n",
      "52:\tlearn: 0.6224279\ttotal: 2.65s\tremaining: 2.35s\n",
      "53:\tlearn: 0.6213763\ttotal: 2.69s\tremaining: 2.29s\n",
      "54:\tlearn: 0.6203599\ttotal: 2.75s\tremaining: 2.25s\n",
      "55:\tlearn: 0.6192506\ttotal: 2.81s\tremaining: 2.2s\n",
      "56:\tlearn: 0.6182083\ttotal: 2.86s\tremaining: 2.16s\n",
      "57:\tlearn: 0.6171891\ttotal: 2.92s\tremaining: 2.12s\n",
      "58:\tlearn: 0.6160964\ttotal: 2.98s\tremaining: 2.07s\n",
      "59:\tlearn: 0.6149669\ttotal: 3.02s\tremaining: 2.02s\n",
      "60:\tlearn: 0.6139068\ttotal: 3.08s\tremaining: 1.97s\n",
      "61:\tlearn: 0.6129563\ttotal: 3.14s\tremaining: 1.92s\n",
      "62:\tlearn: 0.6120295\ttotal: 3.2s\tremaining: 1.88s\n",
      "63:\tlearn: 0.6109456\ttotal: 3.26s\tremaining: 1.83s\n",
      "64:\tlearn: 0.6098286\ttotal: 3.29s\tremaining: 1.77s\n",
      "65:\tlearn: 0.6087580\ttotal: 3.34s\tremaining: 1.72s\n",
      "66:\tlearn: 0.6078516\ttotal: 3.4s\tremaining: 1.67s\n",
      "67:\tlearn: 0.6067349\ttotal: 3.45s\tremaining: 1.62s\n",
      "68:\tlearn: 0.6056706\ttotal: 3.49s\tremaining: 1.57s\n",
      "69:\tlearn: 0.6046767\ttotal: 3.52s\tremaining: 1.51s\n",
      "70:\tlearn: 0.6037314\ttotal: 3.55s\tremaining: 1.45s\n",
      "71:\tlearn: 0.6026275\ttotal: 3.6s\tremaining: 1.4s\n",
      "72:\tlearn: 0.6015378\ttotal: 3.64s\tremaining: 1.35s\n",
      "73:\tlearn: 0.6006082\ttotal: 3.7s\tremaining: 1.3s\n",
      "74:\tlearn: 0.5996317\ttotal: 3.78s\tremaining: 1.26s\n",
      "75:\tlearn: 0.5986745\ttotal: 3.82s\tremaining: 1.21s\n",
      "76:\tlearn: 0.5977761\ttotal: 3.84s\tremaining: 1.15s\n",
      "77:\tlearn: 0.5968473\ttotal: 3.87s\tremaining: 1.09s\n",
      "78:\tlearn: 0.5959047\ttotal: 3.91s\tremaining: 1.04s\n",
      "79:\tlearn: 0.5950544\ttotal: 3.96s\tremaining: 990ms\n",
      "80:\tlearn: 0.5941560\ttotal: 4.03s\tremaining: 944ms\n",
      "81:\tlearn: 0.5932479\ttotal: 4.08s\tremaining: 896ms\n",
      "82:\tlearn: 0.5924155\ttotal: 4.16s\tremaining: 852ms\n",
      "83:\tlearn: 0.5915189\ttotal: 4.22s\tremaining: 804ms\n",
      "84:\tlearn: 0.5906750\ttotal: 4.25s\tremaining: 750ms\n",
      "85:\tlearn: 0.5897535\ttotal: 4.31s\tremaining: 701ms\n",
      "86:\tlearn: 0.5888806\ttotal: 4.37s\tremaining: 653ms\n",
      "87:\tlearn: 0.5879149\ttotal: 4.41s\tremaining: 601ms\n",
      "88:\tlearn: 0.5869947\ttotal: 4.45s\tremaining: 550ms\n",
      "89:\tlearn: 0.5862377\ttotal: 4.51s\tremaining: 501ms\n",
      "90:\tlearn: 0.5853577\ttotal: 4.56s\tremaining: 451ms\n",
      "91:\tlearn: 0.5844184\ttotal: 4.63s\tremaining: 402ms\n",
      "92:\tlearn: 0.5836478\ttotal: 4.68s\tremaining: 353ms\n",
      "93:\tlearn: 0.5827924\ttotal: 4.74s\tremaining: 303ms\n",
      "94:\tlearn: 0.5819458\ttotal: 4.81s\tremaining: 253ms\n",
      "95:\tlearn: 0.5811139\ttotal: 4.85s\tremaining: 202ms\n",
      "96:\tlearn: 0.5802382\ttotal: 4.88s\tremaining: 151ms\n",
      "97:\tlearn: 0.5794839\ttotal: 4.94s\tremaining: 101ms\n",
      "98:\tlearn: 0.5787911\ttotal: 5.01s\tremaining: 50.6ms\n",
      "99:\tlearn: 0.5779909\ttotal: 5.08s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<catboost.core.CatBoostClassifier object at 0x000001EBC46FB160>,\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'depth': [1, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                  10],\n",
       "                                        'iterations': [100, 233, 366, 500],\n",
       "                                        'l2_leaf_reg': [1, 2, 3, 5, 8],\n",
       "                                        'learning_rate': [0.005, 0.03, 0.1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model = CatBoostClassifier()\n",
    "\n",
    "randm = RandomizedSearchCV(estimator=cb_model, param_distributions = params, \n",
    "                               cv = 3, n_iter = 10, n_jobs=-1)\n",
    "randm.fit(X_train, y_train,cat_features=cate_features_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================\n",
      " Results from Random Search \n",
      "========================================================\n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " <catboost.core.CatBoostClassifier object at 0x000001EBC49EE7B8>\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.0\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.005, 'l2_leaf_reg': 8, 'iterations': 100, 'depth': 6}\n",
      "\n",
      " ========================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========================================================\")\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"========================================================\")    \n",
    "\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "      randm.best_estimator_)\n",
    "\n",
    "print(\"\\n The best score across ALL searched params:\\n\",\n",
    "      randm.best_score_)\n",
    "\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "      randm.best_params_)\n",
    "\n",
    "print(\"\\n ========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost_model = CatBoostClassifier(iterations=400,\n",
    "#                                     verbose=True,eval_metric=\"F1\",\n",
    "#                                     learning_rate=0.1,\n",
    "#                                     class_weights=[1,3],\n",
    "#                                     depth=3,l2_leaf_reg=3,bagging_temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### model Evalution started #######################\n",
      "Train Accuracy: 0.8057784911717496 \t Test Accuracy: 0.7835820895522388\n",
      "Train Loss: 0.1942215088282504 \t Test Loss: 0.21641791044776118\n",
      "Train AUC: 0.8633902109483961 \t Test AUC: 0.8573109738158283\n",
      "Train F1: 0.7397849462365591 \t Test F1: 0.712871287128713\n",
      "Train recall: 0.7196652719665272 \t Test recall: 0.6990291262135923\n",
      "Train precision: 0.7610619469026548 \t Test Precision: 0.7272727272727273\n",
      "Train Confusion Matrix: \n",
      "[[330  54]\n",
      " [ 67 172]] \n",
      " Test Confusion Matrix: \n",
      "[[138  27]\n",
      " [ 31  72]]\n"
     ]
    }
   ],
   "source": [
    "model_evalution(catboost_model,X_train, y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y =catboost_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission =pd.DataFrame({'PassengerId':test_passengers.values ,'Survived':test_y}) \n",
    "#submission['Loan_Status'].replace(0, 'N',inplace=True)\n",
    "#submission['Loan_Status'].replace(1, 'Y',inplace=True)\n",
    "import datetime\n",
    "FORMAT = '%Y%m%d%H%M%S'\n",
    "timestamp=datetime.datetime.now().strftime(FORMAT)\n",
    "filename =\"Titanic_CatBoost\"+timestamp+\"_out.csv\"\n",
    "#submission.to_csv(filename,index=False)\n",
    "\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

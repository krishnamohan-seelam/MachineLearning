{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlsettings.settings import load_app_config, get_datafolder_path\n",
    "from mltools.mlcommon import load_data, print_dataset_info, split_dataset, auto_scatter_simple\n",
    "\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "% matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEV': {'ML_PATH': 'F:\\\\MachineLearning', 'ML_DATASOURCE': 'F:\\\\DataSource'}, 'UAT': {'ML_PATH': 'F:\\\\MachineLearning', 'ML_DATASOURCE': 'F:\\\\DataSource'}, 'REG': {'ML_PATH': 'F:\\\\MachineLearning', 'ML_DATASOURCE': 'F:\\\\DataSource'}, 'PRD': {'ML_PATH': 'F:\\\\MachineLearning', 'ML_DATASOURCE': 'F:\\\\DataSource'}}\n",
      "Adding F:\\MachineLearning  to system path\n",
      "Adding F:\\DataSource  to system path\n"
     ]
    }
   ],
   "source": [
    "load_app_config()\n",
    "DIRECTORY = \"titanic\"\n",
    "TRAINFILENAME = \"train.csv\"\n",
    "TESTFILENAME = \"test.csv\"\n",
    "FILENAME ='titanic.csv'\n",
    "ALL_COLUMNS = ['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin',\n",
    "               'Embarked']\n",
    "\n",
    "X_COLUMNS = ['Fare', 'Pclass', 'Sex_Bin', 'Age', 'SibSp']\n",
    "Y_COLUMNS = ['Survived']\n",
    "TRAINING_MODE =True\n",
    "input_path = get_datafolder_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start_classification(dc_model ,filename=FILENAME, is_training=True):\n",
    "    \n",
    "    print(\"start_classification\")\n",
    "    \n",
    "    input_file = os.path.join(input_path, DIRECTORY, filename)\n",
    "\n",
    "    input_dataset = load_data(input_file)\n",
    "    print(\" input file is :{0} loaded.\".format(input_file))\n",
    "    \n",
    "    train=input_dataset.sample(frac=0.8,random_state=1)\n",
    "    display_dataset_info(train)\n",
    "    \n",
    "    test=input_dataset.drop(train.index)\n",
    "     \n",
    "    train_y =train['Survived']\n",
    "    train = train.drop(['Survived'],axis=1)\n",
    "    train_X =clean_dataset(train)[X_COLUMNS]\n",
    "    train_model(dc_model,train_X,train_y)\n",
    "    \n",
    "    #display_dataset_info(test)\n",
    "    test_y =test['Survived']\n",
    "    test = test.drop(['Survived'],axis=1)\n",
    "    test_X =clean_dataset(test)[X_COLUMNS]\n",
    "    test_model(dc_model,test_X,test_y,test,filename)\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def train_model(dc_model,train_X,train_y):\n",
    "    \n",
    "    dc_model.fit(train_X,train_y)\n",
    "    acc_decision_tree = round(dc_model.score(train_X, train_y), 4)\n",
    "    print(\"Training Accuracy: %0.4f\" % (acc_decision_tree))\n",
    "\n",
    "def test_model(dc_model,test_X,test_y,test,filename):\n",
    "    test_set =pd.DataFrame(test_X,columns=X_COLUMNS)\n",
    "    print(test_set.head(5))\n",
    "    print(\"Test Size {0}\".format(test_set.shape))\n",
    "    \n",
    "    FORMAT = '%Y%m%d%H%M%S'\n",
    "    timestamp=datetime.datetime.now().strftime(FORMAT)\n",
    "    filename_appender =\"_\"+timestamp+\"_out.csv\"\n",
    "    out_filename =os.path.join(input_path, DIRECTORY, filename.replace(\".csv\",filename_appender))\n",
    "\n",
    "    print(\"Predictions are written to  {0}\".format(out_filename))\n",
    "    predict_y = dc_model.predict(test_X)\n",
    "    \n",
    "    print(\"Accuracy is \", accuracy_score(test_y,predict_y)*100)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    pd.DataFrame(\n",
    "    confusion_matrix(test_y, predict_y),\n",
    "    columns=['Predicted Not Survival', 'Predicted Survival'],\n",
    "    index=['True Not Survival', 'True Survival'])\n",
    "    \n",
    "    test[\"Survived\"] =test_y\n",
    "    test[\"Predict_Survived\"] =predict_y\n",
    "    test['Prediction_Result'] = np.where(test['Survived'] ==test['Predict_Survived']  , 'CORRECT', 'INCORRECT')\n",
    "    \n",
    "    test.to_csv(out_filename,index = False)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(pd.DataFrame(\n",
    "    confusion_matrix(test_y, predict_y),\n",
    "    columns=['Predicted Not Survival', 'Predicted Survival'],\n",
    "    index=['True Not Survival', 'True Survival']\n",
    "    ))\n",
    "    \n",
    "def visualize_dataset(input_dataset):\n",
    "    continuous_vars = input_dataset.describe().columns\n",
    "    categorical_vars = input_dataset.describe(include=[\"object\"]).columns\n",
    "    input_dataset.hist(column=continuous_vars, figsize = (16,16))\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(16, 16))\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.7, hspace=0.3)\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        if i > 9:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "        sns.countplot(y = categorical_vars[i], data=input_dataset, ax=ax)\n",
    "    \n",
    "     \n",
    "    \n",
    "def learn_model(dc_model,input_dataset_cleaned):\n",
    "    X_values = input_dataset_cleaned[X_COLUMNS]\n",
    "    y_values = input_dataset_cleaned[Y_COLUMNS]\n",
    "    dc_model.fit(X_values,y_values)\n",
    "\n",
    "\n",
    "def display_dataset_info(input_dataset):\n",
    "    print(input_dataset.info())\n",
    "     \n",
    "    #print(input_dataset.head(4).to_string())\n",
    "    #print(input_dataset.head(4))\n",
    "    #print(\"Data set counts:\")\n",
    "    #print(input_dataset.count())\n",
    "   \n",
    "\n",
    "\n",
    "def clean_dataset(input_dataset):\n",
    "    columns_to_dropped = ['Cabin', 'Ticket']\n",
    "    process_dataset = input_dataset.drop(columns_to_dropped, axis=1)\n",
    "    class_le = LabelEncoder()\n",
    "    class_lb = LabelBinarizer()\n",
    "    sex_bin = class_lb.fit_transform(process_dataset['Sex'].values)\n",
    "    process_dataset['Sex_Bin'] = sex_bin\n",
    "\n",
    "    mean_age = math.ceil(process_dataset[\"Age\"].mean())\n",
    "    # print(\"average age {0}\".format(mean_age))\n",
    "    process_dataset[\"Age\"] = process_dataset[\"Age\"].fillna(mean_age)\n",
    "    process_dataset[\"Embarked\"] = process_dataset[\"Embarked\"].fillna(\"NA\")\n",
    "    Embarked_EC = class_le.fit_transform(process_dataset[\"Embarked\"])\n",
    "\n",
    "    process_dataset[\"Embarked_EC\"] = Embarked_EC\n",
    "\n",
    "    median_fare = math.ceil(process_dataset[\"Fare\"].median())\n",
    "    process_dataset[\"Fare\"] = process_dataset[\"Fare\"].fillna(median_fare)\n",
    "    # print(\"age {0}\".format(process_dataset[\"Age\"].unique()))\n",
    "    return process_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_classification\n",
      " input file is :F:\\DataSource\\titanic\\titanic.csv loaded.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1047 entries, 201 to 781\n",
      "Data columns (total 11 columns):\n",
      "Pclass      1047 non-null int64\n",
      "Survived    1047 non-null int64\n",
      "Name        1047 non-null object\n",
      "Sex         1047 non-null object\n",
      "Age         837 non-null float64\n",
      "SibSp       1047 non-null int64\n",
      "Parch       1047 non-null int64\n",
      "Ticket      1047 non-null object\n",
      "Fare        1046 non-null float64\n",
      "Cabin       242 non-null object\n",
      "Embarked    1045 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 98.2+ KB\n",
      "None\n",
      "Training Accuracy: 0.8357\n",
      "        Fare  Pclass  Sex_Bin   Age  SibSp\n",
      "15   25.9250       1        1  31.0      0\n",
      "20   52.5542       1        1  37.0      1\n",
      "21   52.5542       1        0  47.0      1\n",
      "24  221.7792       1        0  29.0      0\n",
      "25   26.0000       1        1  25.0      0\n",
      "Test Size (262, 5)\n",
      "Predictions are written to  F:\\DataSource\\titanic\\titanic_20171111190029_out.csv\n",
      "Accuracy is  75.572519084\n",
      "                   Predicted Not Survival  Predicted Survival\n",
      "True Not Survival                     143                  28\n",
      "True Survival                          36                  55\n",
      "F:\\DataSource\\titanic\\titanic_out.dot\n"
     ]
    }
   ],
   "source": [
    "#dc_model = DecisionTreeClassifier(max_depth=5 ,random_state=1)\n",
    "dc_model = DecisionTreeClassifier(criterion = \"entropy\",max_depth=5 ,random_state=1)\n",
    "start_classification(dc_model,FILENAME,TRAINING_MODE)\n",
    "input_path = get_datafolder_path()\n",
    "out_dot_file =os.path.join(input_path, DIRECTORY, FILENAME.replace(\".csv\",\"_out.dot\"))\n",
    "print(out_dot_file)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(dc_model, out_file=dot_data,  \n",
    "                         feature_names=X_COLUMNS)  \n",
    "#print(dot_data.getvalue())\n",
    "graph = pydotplus.graphviz.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
